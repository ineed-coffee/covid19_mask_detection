{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 4 haarcascade models from [openCV github](https://github.com/opencv/opencv/tree/master/data/haarcascades)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cascade Classifiers 로드__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "glass_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "eyesplit_cascade = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__advanced_eye_detect 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_eye_detect(img,cascade,info):\n",
    "    \n",
    "    ret_val=[]\n",
    "    \n",
    "    img_gray =  cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img_gray)\n",
    "    \n",
    "    if len(faces)!=1:\n",
    "        return ret_val\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = img_gray[y:y+h, x:x+w]\n",
    "        eyes =cascade.detectMultiScale(roi_gray,1.1,4)\n",
    "    \n",
    "    if not (len(eyes)==2):    \n",
    "        if info == 'normal':\n",
    "            return advanced_eye_detect(img,eyesplit_cascade,'split')\n",
    "        elif info == 'split':\n",
    "            return advanced_eye_detect(img,glass_cascade,'glasses')\n",
    "        elif info == 'glasses':\n",
    "            return ret_val\n",
    "        \n",
    "    ret_val = eyes\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get_rotated_image 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotated_image(img,eyes):\n",
    "    \n",
    "    eye_1 , eye_2 = eyes\n",
    "\n",
    "    if eye_1[0] < eye_2[0]:\n",
    "        left_eye = eye_1\n",
    "        right_eye = eye_2\n",
    "    else:\n",
    "        left_eye = eye_2\n",
    "        right_eye = eye_1\n",
    "        \n",
    "    left_eye_center = (int(left_eye[0] + (left_eye[2] / 2)), int(left_eye[1] + (left_eye[3] / 2)))\n",
    "    right_eye_center = (int(right_eye[0] + (right_eye[2]/2)), int(right_eye[1] + (right_eye[3]/2)))\n",
    "    \n",
    "    left_eye_x , left_eye_y = left_eye_center \n",
    "    right_eye_x , right_eye_y = right_eye_center\n",
    "\n",
    "    \n",
    "    delta_x = right_eye_x - left_eye_x\n",
    "    delta_y = right_eye_y - left_eye_y\n",
    "    \n",
    "    if not delta_x or delta_y:\n",
    "        return img\n",
    "    \n",
    "    angle=np.arctan(delta_y/delta_x)\n",
    "    angle = (angle * 180) / np.pi\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, (angle), 1.0)\n",
    "    rotated_img = cv2.warpAffine(img, M, (w, h))\n",
    "  \n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__calculate_rotated_eyes 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rotated_eyes(rotated_img,cascade,info):\n",
    "\n",
    "    ret_val=[]\n",
    "    \n",
    "    rotated_gray = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(rotated_gray, 1.1, 4)\n",
    "    \n",
    "    if len(faces)!=1:\n",
    "        return ret_val\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        black=np.zeros(rotated_gray.shape,dtype='uint8')\n",
    "        black[y:y+h, x:x+w]=rotated_gray[y:y+h, x:x+w]\n",
    "\n",
    "        rotated_eyes =cascade.detectMultiScale(black,1.1,4)    \n",
    "    \n",
    "    if len(rotated_eyes)!=2:    \n",
    "        if info == 'normal':\n",
    "            return calculate_rotated_eyes(rotated_img,glass_cascade,'glasses')\n",
    "        elif info == 'glasses':\n",
    "            return ret_val\n",
    "    \n",
    "    ret_val = rotated_eyes\n",
    "    \n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__extract_facial_mask_area 함수 정의__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facial_mask_area(rotated_img,rotated_eyes):\n",
    "    \n",
    "    eye_1 , eye_2 = rotated_eyes\n",
    "\n",
    "    if eye_1[0] < eye_2[0]:\n",
    "        left_eye = eye_1\n",
    "        right_eye = eye_2\n",
    "    else:\n",
    "        left_eye = eye_2\n",
    "        right_eye = eye_1\n",
    "    \n",
    "    left_eye_center = (int(left_eye[0] + (left_eye[2] / 2)), int(left_eye[1] + (left_eye[3] / 2)))\n",
    "    right_eye_center = (int(right_eye[0] + (right_eye[2]/2)), int(right_eye[1] + (right_eye[3]/2)))\n",
    "    \n",
    "    left_eye_x , left_eye_y = left_eye_center \n",
    "    right_eye_x , right_eye_y = right_eye_center\n",
    "    \n",
    "    delta_x = right_eye_x - left_eye_x\n",
    "    delta_y = right_eye_y - left_eye_y\n",
    "    \n",
    "    L = np.sqrt(delta_x**2 + delta_y**2)\n",
    "    xpad_L , xpad_R = int(0.6*L) , int(1.6*L)\n",
    "    ypad_U , ypad_D = int(0.6*L) , int(1.8*L)\n",
    "    \n",
    "    ROI = rotated_img[left_eye_y-ypad_U:left_eye_y+ypad_D,left_eye_x-xpad_L:left_eye_x+xpad_R]\n",
    "    ROI_resized = cv2.resize(ROI,(120,140))\n",
    "    mask_area = ROI_resized[50:140,0:120]\n",
    "    \n",
    "    return mask_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__메인 코드__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if full_path ==  \n",
    "- C:/images/no_mask  \n",
    "- C:/images/nose_mask  \n",
    "- C:/images/chin_mask  \n",
    "- C:/images/full_mask  \n",
    "***\n",
    "upper_path = C:/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_path=\"D:/test\"\n",
    "types_=[\"no_mask\",\"nose_mask\",\"chin_mask\",\"full_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 622 area with type : no_mask\n",
      "Extracted 371 area with type : nose_mask\n",
      "Extracted 631 area with type : chin_mask\n",
      "Extracted 153 area with type : full_mask\n"
     ]
    }
   ],
   "source": [
    "lens=[]\n",
    "for type_ in types_:\n",
    "    \n",
    "    img_path = os.path.join(upper_path,type_)\n",
    "    save_path = os.path.join(upper_path,type_+\"_extracted\")\n",
    "    if not os.path.isdir(save_path): os.mkdir(save_path)\n",
    "\n",
    "    files = os.listdir(img_path)\n",
    "    image_files = [file for file in files if file.endswith(\".png\")]\n",
    "    extracted_cnt=0\n",
    "    for file in image_files:\n",
    "\n",
    "        image=cv2.imread(img_path+\"/\"+file)\n",
    "\n",
    "        if image.shape[0]<400 or image.shape[1]<400 :\n",
    "            w,h,c = image.shape\n",
    "            image = cv2.resize(image,(h*2,w*2))\n",
    "\n",
    "        eyes = advanced_eye_detect(image,eye_cascade,'normal')\n",
    "\n",
    "        if len(eyes)!=2:\n",
    "            continue\n",
    "\n",
    "        rotated_image = get_rotated_image(image,eyes)\n",
    "        rotated_eyes = calculate_rotated_eyes(rotated_image,eye_cascade,'normal')\n",
    "\n",
    "        if len(rotated_eyes)!=2:\n",
    "            continue\n",
    "\n",
    "        current_mask_area = extract_facial_mask_area(rotated_image,rotated_eyes)\n",
    "        extracted_cnt+=1\n",
    "        cv2.imwrite(os.path.join(save_path,file), current_mask_area) # replace it with your path\n",
    "    \n",
    "    lens.append(extracted_cnt)\n",
    "    print(f\"Extracted {extracted_cnt} area with type : {type_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train | Validate | Test split (7:2:1)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(1120)\n",
    "\n",
    "split_path = upper_path+'/'+'dataset' # 저장할 경로 (안에 빈 train , test 폴더 먼저 만들어 놓고 실행)\n",
    "match_size=min(lens)\n",
    "\n",
    "if not os.path.isdir(split_path):os.mkdir(split_path)\n",
    "if not os.path.isdir(os.path.join(split_path,\"train\")):os.mkdir(os.path.join(split_path,\"train\"))\n",
    "if not os.path.isdir(os.path.join(split_path,\"val\")):os.mkdir(os.path.join(split_path,\"val\"))\n",
    "if not os.path.isdir(os.path.join(split_path,\"test\")):os.mkdir(os.path.join(split_path,\"test\"))\n",
    "\n",
    "for type_ in types_:\n",
    "    train_path = os.path.join(os.path.join(split_path,\"train\"),type_)\n",
    "    val_path = os.path.join(os.path.join(split_path,\"val\"),type_)\n",
    "    test_path = os.path.join(os.path.join(split_path,\"test\"),type_)\n",
    "    \n",
    "    if not os.path.isdir(train_path):os.mkdir(train_path)\n",
    "    if not os.path.isdir(val_path):os.mkdir(val_path)\n",
    "    if not os.path.isdir(test_path):os.mkdir(test_path)\n",
    "    \n",
    "    files = os.listdir(upper_path+\"/\"+type_+\"_extracted\")\n",
    "    \n",
    "    image_files = [file for file in files if file.endswith(\".png\")]\n",
    "    \n",
    "    samples = random.sample(image_files,match_size)\n",
    "    \n",
    "    train,test = train_test_split(samples,test_size=0.1,random_state=1120)\n",
    "    train,validate = train_test_split(train,test_size=(2/9),random_state=1120)\n",
    "    \n",
    "    for img in train:\n",
    "        shutil.copy(upper_path+\"/\"+type_+\"_extracted/\"+img,train_path+'/'+img)\n",
    "        \n",
    "    for img in validate:\n",
    "        shutil.copy(upper_path+\"/\"+type_+\"_extracted/\"+img,val_path+'/'+img)\n",
    "        \n",
    "    for img in test:\n",
    "        shutil.copy(upper_path+\"/\"+type_+\"_extracted/\"+img,test_path+'/'+img)\n",
    "    \n",
    "print(\"Split done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
